{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Cambios con Sentinel-1 en Municipios de Casanare y Meta\n",
    "## Parte 3: Análisis de Detección de Cambios\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Este notebook implementa algoritmos de detección de cambios en series temporales de imágenes Sentinel-1 SAR. La metodología se basa en el análisis estadístico multivariado de cambios propuesto por Conradsen et al. [1] y adaptado por Canty et al. [2] para Google Earth Engine.\n",
    "\n",
    "### Marco Teórico\n",
    "\n",
    "#### Test de Razón de Verosimilitud (Likelihood Ratio Test)\n",
    "\n",
    "Para detectar cambios en imágenes SAR de polarización dual, se utiliza el test de razón de verosimilitud complejo de Wishart [1]. Para dos imágenes SAR adquiridas en tiempos $t_1$ y $t_2$, la estadística de prueba $Q$ se define como:\n",
    "\n",
    "$$Q = \\frac{|\\Sigma_1 + \\Sigma_2|^{2n}}{|\\Sigma_1|^n |\\Sigma_2|^n}$$\n",
    "\n",
    "donde $\\Sigma_i$ son las matrices de covarianza para cada fecha y $n$ es el número de looks equivalentes.\n",
    "\n",
    "#### Extensión a Series Temporales\n",
    "\n",
    "Para series temporales de $k$ imágenes, el test se aplica secuencialmente para detectar el momento y la magnitud de cambios [3]. Un cambio es detectado cuando:\n",
    "\n",
    "$$-2\\rho\\ln Q > \\chi^2_{\\alpha, f}$$\n",
    "\n",
    "donde $\\rho$ es un factor de corrección, $\\alpha$ es el nivel de significancia y $f$ son los grados de libertad.\n",
    "\n",
    "### Métodos Complementarios\n",
    "\n",
    "Además del método estadístico, se implementarán:\n",
    "1. **Análisis de diferencias temporales**: Diferencias absolutas y relativas de backscatter\n",
    "2. **Análisis de anomalías**: Detección de desviaciones respecto a la media temporal\n",
    "3. **Índices de cambio**: NDCV (Normalized Difference Change Vector)\n",
    "\n",
    "---\n",
    "\n",
    "### Referencias\n",
    "\n",
    "[1] K. Conradsen, A. A. Nielsen, J. Schou, and H. Skriver, \"A test statistic in the complex Wishart distribution and its application to change detection in polarimetric SAR data,\" *IEEE Trans. Geosci. Remote Sens.*, vol. 41, no. 1, pp. 4–19, Jan. 2003.\n",
    "\n",
    "[2] M. J. Canty, A. A. Nielsen, H. Skriver, and K. Conradsen, \"Statistical analysis of changes in Sentinel-1 time series on the Google Earth Engine,\" *Remote Sens.*, vol. 12, no. 1, p. 46, Jan. 2020.\n",
    "\n",
    "[3] A. A. Nielsen, K. Conradsen, and H. Skriver, \"Omnibus test for change detection in a time sequence of polarimetric SAR data,\" in *Proc. IEEE IGARSS*, 2015, pp. 3398–3401.\n",
    "\n",
    "[4] Y. Bazi, L. Bruzzone, and F. Melgani, \"An unsupervised approach based on the generalized Gaussian model to automatic change detection in multitemporal SAR images,\" *IEEE Trans. Geosci. Remote Sens.*, vol. 43, no. 4, pp. 874–887, Apr. 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Librerías y Datos Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Inicializar Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"Earth Engine inicializado correctamente\")\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "    print(\"Earth Engine autenticado e inicializado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de notebooks anteriores\n",
    "municipios_seleccionados = gpd.read_file(\"data/municipios_seleccionados.gpkg\", layer=\"municipios\")\n",
    "\n",
    "with open('data/parametros.json', 'r') as f:\n",
    "    parametros = json.load(f)\n",
    "\n",
    "with open('data/procesamiento_info.json', 'r') as f:\n",
    "    proc_info = json.load(f)\n",
    "\n",
    "print(f\"Datos cargados:\")\n",
    "print(f\"  Municipios: {len(municipios_seleccionados)}\")\n",
    "print(f\"  Período: {parametros['fecha_inicio']} a {parametros['fecha_fin']}\")\n",
    "print(f\"  Composiciones disponibles: {proc_info['n_composites']}\")\n",
    "print(f\"  Órbita: {proc_info['orbit_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recrear AOI y colecciones de Earth Engine\n",
    "def gdf_to_ee_geometry(gdf):\n",
    "    geom_union = gdf.geometry.unary_union\n",
    "    if geom_union.geom_type == 'Polygon':\n",
    "        coords = [list(geom_union.exterior.coords)]\n",
    "        return ee.Geometry.Polygon(coords)\n",
    "    elif geom_union.geom_type == 'MultiPolygon':\n",
    "        coords = [list(poly.exterior.coords) for poly in geom_union.geoms]\n",
    "        return ee.Geometry.MultiPolygon(coords)\n",
    "\n",
    "aoi = gdf_to_ee_geometry(municipios_seleccionados)\n",
    "print(\"AOI recreada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recreación de la Colección Sentinel-1 Procesada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recrear el pipeline de procesamiento del Notebook 2\n",
    "def process_sentinel1_collection(aoi, start_date, end_date, orbit_type):\n",
    "    \"\"\"Recrea la colección procesada de Sentinel-1\"\"\"\n",
    "    \n",
    "    # Cargar colección\n",
    "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "        .filterBounds(aoi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')) \\\n",
    "        .filter(ee.Filter.eq('orbitProperties_pass', orbit_type))\n",
    "    \n",
    "    # Conversión a dB\n",
    "    def to_dB(image):\n",
    "        vv = image.select('VV')\n",
    "        vh = image.select('VH')\n",
    "        vv_db = ee.Image(10).multiply(vv.log10()).rename('VV')\n",
    "        vh_db = ee.Image(10).multiply(vh.log10()).rename('VH')\n",
    "        ratio = vv.divide(vh).log10().multiply(10).rename('VV_VH_ratio')\n",
    "        return image.addBands(vv_db).addBands(vh_db).addBands(ratio) \\\n",
    "            .copyProperties(image, ['system:time_start'])\n",
    "    \n",
    "    # Filtro de speckle\n",
    "    def apply_speckle_filter(image):\n",
    "        kernel = ee.Kernel.square(radius=3, units='pixels')\n",
    "        vv_f = image.select('VV').focal_median(kernel=kernel).rename('VV_filtered')\n",
    "        vh_f = image.select('VH').focal_median(kernel=kernel).rename('VH_filtered')\n",
    "        ratio_f = image.select('VV_VH_ratio').focal_median(kernel=kernel).rename('ratio_filtered')\n",
    "        return image.addBands(vv_f).addBands(vh_f).addBands(ratio_f)\n",
    "    \n",
    "    s1_processed = s1.map(to_dB).map(apply_speckle_filter)\n",
    "    \n",
    "    return s1_processed\n",
    "\n",
    "# Procesar colección\n",
    "s1_collection = process_sentinel1_collection(\n",
    "    aoi,\n",
    "    parametros['fecha_inicio'],\n",
    "    parametros['fecha_fin'],\n",
    "    proc_info['orbit_type']\n",
    ")\n",
    "\n",
    "print(f\"Colección recreada: {s1_collection.size().getInfo()} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Método 1: Análisis de Diferencias Temporales\n",
    "\n",
    "El método más simple pero efectivo: calcular diferencias entre períodos de referencia y análisis [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir períodos de referencia y análisis\n",
    "# Ejemplo: comparar mismo período en años diferentes para detectar cambios agrícolas\n",
    "\n",
    "# Período de referencia (baseline): primer semestre 2023\n",
    "reference_start = '2023-01-01'\n",
    "reference_end = '2023-06-30'\n",
    "\n",
    "# Período de análisis (target): primer semestre 2024\n",
    "target_start = '2024-01-01'\n",
    "target_end = '2024-06-30'\n",
    "\n",
    "print(f\"Período de referencia: {reference_start} a {reference_end}\")\n",
    "print(f\"Período de análisis: {target_start} a {target_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear composiciones para cada período\n",
    "reference_composite = s1_collection \\\n",
    "    .filterDate(reference_start, reference_end) \\\n",
    "    .median() \\\n",
    "    .clip(aoi)\n",
    "\n",
    "target_composite = s1_collection \\\n",
    "    .filterDate(target_start, target_end) \\\n",
    "    .median() \\\n",
    "    .clip(aoi)\n",
    "\n",
    "# Calcular número de imágenes en cada composición\n",
    "n_ref = s1_collection.filterDate(reference_start, reference_end).size().getInfo()\n",
    "n_target = s1_collection.filterDate(target_start, target_end).size().getInfo()\n",
    "\n",
    "print(f\"\\nImágenes en período de referencia: {n_ref}\")\n",
    "print(f\"Imágenes en período de análisis: {n_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular diferencias\n",
    "# Diferencia absoluta: target - reference\n",
    "diff_vv = target_composite.select('VV_filtered').subtract(\n",
    "    reference_composite.select('VV_filtered')\n",
    ").rename('diff_VV')\n",
    "\n",
    "diff_vh = target_composite.select('VH_filtered').subtract(\n",
    "    reference_composite.select('VH_filtered')\n",
    ").rename('diff_VH')\n",
    "\n",
    "# Diferencia relativa (porcentual)\n",
    "rel_diff_vv = target_composite.select('VV_filtered').subtract(\n",
    "    reference_composite.select('VV_filtered')\n",
    ").divide(\n",
    "    reference_composite.select('VV_filtered').abs()\n",
    ").multiply(100).rename('rel_diff_VV')\n",
    "\n",
    "rel_diff_vh = target_composite.select('VH_filtered').subtract(\n",
    "    reference_composite.select('VH_filtered')\n",
    ").divide(\n",
    "    reference_composite.select('VH_filtered').abs()\n",
    ").multiply(100).rename('rel_diff_VH')\n",
    "\n",
    "# Magnitud de cambio (vector de cambio)\n",
    "change_magnitude = diff_vv.pow(2).add(diff_vh.pow(2)).sqrt().rename('change_magnitude')\n",
    "\n",
    "print(\"Capas de cambio calculadas:\")\n",
    "print(\"  - Diferencia absoluta VV y VH\")\n",
    "print(\"  - Diferencia relativa VV y VH\")\n",
    "print(\"  - Magnitud de cambio (vector)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Método 2: Análisis de Anomalías\n",
    "\n",
    "Detectar anomalías calculando desviaciones respecto a la media y desviación estándar temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estadísticas temporales para toda la serie\n",
    "mean_vv = s1_collection.select('VV_filtered').mean().clip(aoi)\n",
    "std_vv = s1_collection.select('VV_filtered').reduce(ee.Reducer.stdDev()).clip(aoi)\n",
    "\n",
    "mean_vh = s1_collection.select('VH_filtered').mean().clip(aoi)\n",
    "std_vh = s1_collection.select('VH_filtered').reduce(ee.Reducer.stdDev()).clip(aoi)\n",
    "\n",
    "# Calcular Z-score para el período de análisis\n",
    "# Z = (valor - media) / desviación estándar\n",
    "z_score_vv = target_composite.select('VV_filtered').subtract(mean_vv).divide(std_vv).rename('z_score_VV')\n",
    "z_score_vh = target_composite.select('VH_filtered').subtract(mean_vh).divide(std_vh).rename('z_score_VH')\n",
    "\n",
    "# Detectar anomalías significativas (|Z| > 2 = ~95% confianza)\n",
    "anomaly_vv = z_score_vv.abs().gt(2).rename('anomaly_VV')\n",
    "anomaly_vh = z_score_vh.abs().gt(2).rename('anomaly_VH')\n",
    "\n",
    "# Anomalías en ambas polarizaciones\n",
    "anomaly_both = anomaly_vv.And(anomaly_vh).rename('anomaly_both')\n",
    "\n",
    "print(\"Análisis de anomalías completado\")\n",
    "print(\"Umbral de significancia: |Z-score| > 2 (95% confianza)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Método 3: Índice Normalizado de Vector de Cambio (NDCV)\n",
    "\n",
    "Un índice que normaliza la magnitud del cambio respecto a la suma de intensidades [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCV = |target - reference| / (target + reference)\n",
    "# Valores cercanos a 1 indican cambio fuerte, cercanos a 0 indican no cambio\n",
    "\n",
    "def calculate_ndcv(band_name):\n",
    "    \"\"\"Calcula el Índice Normalizado de Vector de Cambio para una banda\"\"\"\n",
    "    ref_band = reference_composite.select(band_name)\n",
    "    target_band = target_composite.select(band_name)\n",
    "    \n",
    "    # Convertir de dB a lineal para el cálculo\n",
    "    ref_linear = ee.Image(10).pow(ref_band.divide(10))\n",
    "    target_linear = ee.Image(10).pow(target_band.divide(10))\n",
    "    \n",
    "    # NDCV\n",
    "    ndcv = target_linear.subtract(ref_linear).abs().divide(\n",
    "        target_linear.add(ref_linear)\n",
    "    )\n",
    "    \n",
    "    return ndcv\n",
    "\n",
    "ndcv_vv = calculate_ndcv('VV_filtered').rename('NDCV_VV')\n",
    "ndcv_vh = calculate_ndcv('VH_filtered').rename('NDCV_VH')\n",
    "\n",
    "# NDCV combinado (promedio de ambas polarizaciones)\n",
    "ndcv_combined = ndcv_vv.add(ndcv_vh).divide(2).rename('NDCV_combined')\n",
    "\n",
    "# Umbral de cambio significativo (típicamente > 0.3)\n",
    "change_mask = ndcv_combined.gt(0.3).rename('change_mask')\n",
    "\n",
    "print(\"NDCV calculado\")\n",
    "print(\"Umbral de cambio: NDCV > 0.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clasificación de Tipos de Cambio\n",
    "\n",
    "Categorizar los cambios detectados según su naturaleza (aumento/disminución en backscatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar cambios basados en dirección y magnitud\n",
    "# Clases:\n",
    "# 0: Sin cambio\n",
    "# 1: Aumento fuerte (posible crecimiento vegetación, inundación)\n",
    "# 2: Disminución fuerte (posible cosecha, deforestación, sequía)\n",
    "# 3: Cambio moderado positivo\n",
    "# 4: Cambio moderado negativo\n",
    "\n",
    "# Umbrales (en dB)\n",
    "strong_threshold = 3  # cambio > 3 dB es significativo\n",
    "moderate_threshold = 1.5  # cambio entre 1.5-3 dB es moderado\n",
    "\n",
    "# Inicializar con clase 0 (sin cambio)\n",
    "change_classification = ee.Image(0).clip(aoi)\n",
    "\n",
    "# Usar VV para clasificación (más sensible a cambios estructurales)\n",
    "diff_vv_value = diff_vv\n",
    "\n",
    "# Aumento fuerte\n",
    "change_classification = change_classification.where(\n",
    "    diff_vv_value.gt(strong_threshold),\n",
    "    1\n",
    ")\n",
    "\n",
    "# Disminución fuerte\n",
    "change_classification = change_classification.where(\n",
    "    diff_vv_value.lt(-strong_threshold),\n",
    "    2\n",
    ")\n",
    "\n",
    "# Cambio moderado positivo\n",
    "change_classification = change_classification.where(\n",
    "    diff_vv_value.gt(moderate_threshold).And(diff_vv_value.lte(strong_threshold)),\n",
    "    3\n",
    ")\n",
    "\n",
    "# Cambio moderado negativo\n",
    "change_classification = change_classification.where(\n",
    "    diff_vv_value.lt(-moderate_threshold).And(diff_vv_value.gte(-strong_threshold)),\n",
    "    4\n",
    ")\n",
    "\n",
    "change_classification = change_classification.rename('change_class')\n",
    "\n",
    "print(\"Clasificación de cambios:\")\n",
    "print(\"  0: Sin cambio\")\n",
    "print(\"  1: Aumento fuerte (> 3 dB)\")\n",
    "print(\"  2: Disminución fuerte (< -3 dB)\")\n",
    "print(\"  3: Aumento moderado (1.5-3 dB)\")\n",
    "print(\"  4: Disminución moderada (-1.5 a -3 dB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Estadísticas de Cambio por Municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer estadísticas de cambio por municipio\n",
    "def extract_change_stats(municipio_geom, municipio_name, departamento):\n",
    "    \"\"\"Extrae estadísticas de cambio para un municipio\"\"\"\n",
    "    \n",
    "    # Estadísticas de diferencias\n",
    "    stats = ee.Dictionary({\n",
    "        'municipio': municipio_name,\n",
    "        'departamento': departamento\n",
    "    })\n",
    "    \n",
    "    # Diferencia media VV y VH\n",
    "    diff_stats = diff_vv.addBands(diff_vh).reduceRegion(\n",
    "        reducer=ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.stdDev(),\n",
    "            sharedInputs=True\n",
    "        ),\n",
    "        geometry=municipio_geom,\n",
    "        scale=10,\n",
    "        maxPixels=1e9\n",
    "    )\n",
    "    \n",
    "    stats = stats.combine(diff_stats)\n",
    "    \n",
    "    # Estadísticas de NDCV\n",
    "    ndcv_stats = ndcv_combined.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=municipio_geom,\n",
    "        scale=10,\n",
    "        maxPixels=1e9\n",
    "    )\n",
    "    \n",
    "    stats = stats.combine(ndcv_stats)\n",
    "    \n",
    "    # Porcentaje de área con cambio\n",
    "    area_total = municipio_geom.area().divide(10000)  # en hectáreas\n",
    "    area_cambio = change_mask.multiply(ee.Image.pixelArea()).divide(10000).reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=municipio_geom,\n",
    "        scale=10,\n",
    "        maxPixels=1e9\n",
    "    ).get('change_mask')\n",
    "    \n",
    "    porcentaje_cambio = ee.Number(area_cambio).divide(area_total).multiply(100)\n",
    "    \n",
    "    stats = stats.set('area_total_ha', area_total)\n",
    "    stats = stats.set('area_cambio_ha', area_cambio)\n",
    "    stats = stats.set('porcentaje_cambio', porcentaje_cambio)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Extrayendo estadísticas por municipio...\")\n",
    "print(\"(Este proceso puede tomar varios minutos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer estadísticas para todos los municipios\n",
    "stats_list = []\n",
    "\n",
    "for idx, row in municipios_seleccionados.iterrows():\n",
    "    geom = row.geometry\n",
    "    \n",
    "    # Convertir a geometría EE\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        coords = [list(geom.exterior.coords)]\n",
    "        ee_geom = ee.Geometry.Polygon(coords)\n",
    "    else:\n",
    "        coords = [list(poly.exterior.coords) for poly in geom.geoms]\n",
    "        ee_geom = ee.Geometry.MultiPolygon(coords)\n",
    "    \n",
    "    # Extraer estadísticas\n",
    "    stats = extract_change_stats(\n",
    "        ee_geom,\n",
    "        row['mpio_cnmbr'],\n",
    "        row['dpto_cnmbr']\n",
    "    ).getInfo()\n",
    "    \n",
    "    stats_list.append(stats)\n",
    "    print(f\"  Procesado: {row['mpio_cnmbr']}, {row['dpto_cnmbr']}\")\n",
    "\n",
    "# Crear DataFrame\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "# Ordenar por porcentaje de cambio\n",
    "stats_df = stats_df.sort_values('porcentaje_cambio', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTADÍSTICAS DE CAMBIO POR MUNICIPIO\")\n",
    "print(\"=\"*80)\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear mapa interactivo\n",
    "Map = geemap.Map(\n",
    "    center=[parametros['centroide_lat'], parametros['centroide_lon']],\n",
    "    zoom=9\n",
    ")\n",
    "\n",
    "# Agregar municipios\n",
    "Map.add_gdf(municipios_seleccionados, layer_name=\"Municipios\", style={'fillOpacity': 0})\n",
    "\n",
    "# Parámetros de visualización\n",
    "vis_sar = {'min': -25, 'max': 0, 'palette': ['blue', 'white', 'green']}\n",
    "vis_diff = {'min': -5, 'max': 5, 'palette': ['red', 'white', 'blue']}\n",
    "vis_ndcv = {'min': 0, 'max': 0.6, 'palette': ['white', 'yellow', 'orange', 'red']}\n",
    "vis_class = {\n",
    "    'min': 0,\n",
    "    'max': 4,\n",
    "    'palette': ['gray', 'blue', 'red', 'lightblue', 'orange']\n",
    "}\n",
    "\n",
    "# Agregar capas\n",
    "Map.addLayer(reference_composite.select('VV_filtered'), vis_sar, 'Referencia VV', shown=False)\n",
    "Map.addLayer(target_composite.select('VV_filtered'), vis_sar, 'Análisis VV', shown=False)\n",
    "Map.addLayer(diff_vv, vis_diff, 'Diferencia VV', shown=True)\n",
    "Map.addLayer(ndcv_combined, vis_ndcv, 'NDCV', shown=True)\n",
    "Map.addLayer(change_classification, vis_class, 'Clasificación de Cambios', shown=True)\n",
    "Map.addLayer(change_mask.selfMask(), {'palette': 'red'}, 'Máscara de Cambio (NDCV>0.3)', shown=False)\n",
    "\n",
    "# Agregar leyenda\n",
    "legend_dict = {\n",
    "    'Sin cambio': 'gray',\n",
    "    'Aumento fuerte (>3dB)': 'blue',\n",
    "    'Disminución fuerte (<-3dB)': 'red',\n",
    "    'Aumento moderado': 'lightblue',\n",
    "    'Disminución moderada': 'orange'\n",
    "}\n",
    "Map.add_legend(legend_dict=legend_dict, title='Tipos de Cambio')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análisis de Patrones Temporales\n",
    "\n",
    "Extraer series temporales para analizar la dinámica de cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear series temporales mensuales para un punto de interés\n",
    "# (Usar el centroide del área de estudio como ejemplo)\n",
    "\n",
    "point_of_interest = ee.Geometry.Point(\n",
    "    [parametros['centroide_lon'], parametros['centroide_lat']]\n",
    ")\n",
    "\n",
    "# Función para extraer valores en un punto\n",
    "def extract_point_values(image):\n",
    "    date = image.date().format('YYYY-MM-dd')\n",
    "    values = image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=point_of_interest.buffer(100),  # buffer de 100m\n",
    "        scale=10\n",
    "    )\n",
    "    return ee.Feature(None, {\n",
    "        'date': date,\n",
    "        'VV': values.get('VV_filtered'),\n",
    "        'VH': values.get('VH_filtered')\n",
    "    })\n",
    "\n",
    "# Extraer serie temporal\n",
    "time_series_fc = s1_collection.map(extract_point_values)\n",
    "time_series_data = time_series_fc.aggregate_array('date').getInfo()\n",
    "vv_values = time_series_fc.aggregate_array('VV').getInfo()\n",
    "vh_values = time_series_fc.aggregate_array('VH').getInfo()\n",
    "\n",
    "# Crear DataFrame\n",
    "ts_df = pd.DataFrame({\n",
    "    'date': pd.to_datetime(time_series_data),\n",
    "    'VV': vv_values,\n",
    "    'VH': vh_values\n",
    "})\n",
    "\n",
    "ts_df = ts_df.sort_values('date')\n",
    "\n",
    "print(f\"Serie temporal extraída: {len(ts_df)} observaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar serie temporal\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# VV\n",
    "axes[0].plot(ts_df['date'], ts_df['VV'], 'b-', linewidth=1, label='VV')\n",
    "axes[0].scatter(ts_df['date'], ts_df['VV'], s=20, c='blue', alpha=0.5)\n",
    "axes[0].axvline(pd.to_datetime(reference_start), color='green', linestyle='--', label='Inicio Referencia')\n",
    "axes[0].axvline(pd.to_datetime(reference_end), color='green', linestyle='--', label='Fin Referencia')\n",
    "axes[0].axvline(pd.to_datetime(target_start), color='red', linestyle='--', label='Inicio Análisis')\n",
    "axes[0].axvline(pd.to_datetime(target_end), color='red', linestyle='--', label='Fin Análisis')\n",
    "axes[0].set_ylabel('Backscatter VV (dB)')\n",
    "axes[0].set_title('Serie Temporal Sentinel-1 - Punto Central del Área de Estudio')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# VH\n",
    "axes[1].plot(ts_df['date'], ts_df['VH'], 'r-', linewidth=1, label='VH')\n",
    "axes[1].scatter(ts_df['date'], ts_df['VH'], s=20, c='red', alpha=0.5)\n",
    "axes[1].axvline(pd.to_datetime(reference_start), color='green', linestyle='--')\n",
    "axes[1].axvline(pd.to_datetime(reference_end), color='green', linestyle='--')\n",
    "axes[1].axvline(pd.to_datetime(target_start), color='red', linestyle='--')\n",
    "axes[1].axvline(pd.to_datetime(target_end), color='red', linestyle='--')\n",
    "axes[1].set_ylabel('Backscatter VH (dB)')\n",
    "axes[1].set_xlabel('Fecha')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/time_series.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Serie temporal guardada en: data/time_series.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar estadísticas de cambio\n",
    "stats_df.to_csv('data/estadisticas_cambio_municipios.csv', index=False)\n",
    "print(\"Estadísticas guardadas en: data/estadisticas_cambio_municipios.csv\")\n",
    "\n",
    "# Guardar serie temporal\n",
    "ts_df.to_csv('data/serie_temporal_punto_central.csv', index=False)\n",
    "print(\"Serie temporal guardada en: data/serie_temporal_punto_central.csv\")\n",
    "\n",
    "# Guardar parámetros del análisis de cambios\n",
    "change_analysis_params = {\n",
    "    'reference_period': {'start': reference_start, 'end': reference_end},\n",
    "    'target_period': {'start': target_start, 'end': target_end},\n",
    "    'n_images_reference': n_ref,\n",
    "    'n_images_target': n_target,\n",
    "    'strong_change_threshold_db': strong_threshold,\n",
    "    'moderate_change_threshold_db': moderate_threshold,\n",
    "    'ndcv_threshold': 0.3,\n",
    "    'z_score_threshold': 2\n",
    "}\n",
    "\n",
    "with open('data/change_analysis_params.json', 'w') as f:\n",
    "    json.dump(change_analysis_params, f, indent=2)\n",
    "\n",
    "print(\"Parámetros de análisis guardados en: data/change_analysis_params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook se implementaron múltiples métodos de detección de cambios:\n",
    "\n",
    "1. ✓ **Análisis de diferencias temporales**: Diferencias absolutas y relativas entre períodos\n",
    "2. ✓ **Análisis de anomalías**: Detección mediante Z-scores\n",
    "3. ✓ **Índice NDCV**: Normalización de cambios\n",
    "4. ✓ **Clasificación de cambios**: 5 categorías según magnitud y dirección\n",
    "5. ✓ **Estadísticas por municipio**: Cuantificación de áreas de cambio\n",
    "6. ✓ **Series temporales**: Análisis de dinámica temporal\n",
    "\n",
    "### Principales hallazgos:\n",
    "\n",
    "- Los municipios están ordenados por porcentaje de área con cambios detectados\n",
    "- Los cambios se clasifican en aumento/disminución de backscatter\n",
    "- Las series temporales muestran la variabilidad estacional\n",
    "\n",
    "### Interpretación agrícola:\n",
    "\n",
    "- **Aumento de backscatter**: Posible crecimiento vegetativo, inundación de cultivos (arroz)\n",
    "- **Disminución de backscatter**: Posible cosecha, preparación de suelo, sequía\n",
    "\n",
    "**Próximo paso**: Notebook 4 - Visualización avanzada e interpretación contextual de resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
